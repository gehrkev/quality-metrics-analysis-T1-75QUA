{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lise de M√©tricas de Qualidade - 75QUA\n",
    "\n",
    "Este notebook analisa as m√©tricas CK, PMD, bugs detectados pelo SpotBugs e refatora√ß√µes detectadas pelo RefactoringMiner em m√∫ltiplas releases de um projeto Java.\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANTE: Execute a An√°lise Primeiro!\n",
    "\n",
    "```bash\n",
    "make analyze REPO=jhy/jsoup\n",
    "# OU\n",
    "make analyze-limit REPO=jhy/jsoup LIMIT=5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURA√á√ÉO - Altere para o nome do seu projeto\n",
    "PROJECT_NAME = \"jsoup\"\n",
    "RESULTS_DIR = Path(f\"/workspace/results/{PROJECT_NAME}\")\n",
    "\n",
    "print(f\"Analisando projeto: {PROJECT_NAME}\")\n",
    "print(f\"Diret√≥rio de resultados: {RESULTS_DIR}\")\n",
    "print(f\"Diret√≥rio existe: {RESULTS_DIR.exists()}\")\n",
    "\n",
    "if RESULTS_DIR.exists():\n",
    "    release_dirs = sorted([d for d in RESULTS_DIR.glob('*') if d.is_dir() and not d.name.startswith('.')])\n",
    "    print(f\"‚úì Encontradas {len(release_dirs)} releases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregar M√©tricas CK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "\n",
    "for release_dir in release_dirs:\n",
    "    class_csv = release_dir / 'ck' / 'class.csv'\n",
    "    \n",
    "    if class_csv.exists():\n",
    "        df = pd.read_csv(class_csv)\n",
    "        df['release'] = release_dir.name\n",
    "        \n",
    "        metadata_file = release_dir / 'metadata.json'\n",
    "        if metadata_file.exists():\n",
    "            with open(metadata_file) as f:\n",
    "                metadata = json.load(f)\n",
    "                df['release_date'] = metadata.get('published_date', '')\n",
    "        \n",
    "        all_metrics.append(df)\n",
    "        print(f\"‚úì {release_dir.name}: {len(df)} classes\")\n",
    "\n",
    "if all_metrics:\n",
    "    df_all = pd.concat(all_metrics, ignore_index=True)\n",
    "    print(f\"\\n‚úì Total de classes: {len(df_all)}\")\n",
    "    print(f\"‚úì Releases: {df_all['release'].nunique()}\")\n",
    "else:\n",
    "    df_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualizar estrutura dos dados\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estat√≠sticas Descritivas por Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    metrics_by_release = df_all.groupby('release').agg({\n",
    "        'wmc': ['mean', 'median', 'std', 'max'],\n",
    "        'dit': ['mean', 'median', 'std', 'max'],\n",
    "        'noc': ['mean', 'median', 'std', 'max'],\n",
    "        'cbo': ['mean', 'median', 'std', 'max'],\n",
    "        'lcom': ['mean', 'median', 'std', 'max'],\n",
    "        'rfc': ['mean', 'median', 'std', 'max'],\n",
    "        'loc': ['sum', 'mean', 'median', 'std']\n",
    "    }).round(2)\n",
    "    \n",
    "    display(metrics_by_release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualiza√ß√£o - Evolu√ß√£o das M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    fig.suptitle('Evolu√ß√£o das 7 M√©tricas CK', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # WMC\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    metrics_by_release[('wmc', 'mean')].plot(ax=ax1, marker='o', color='blue', linewidth=2)\n",
    "    ax1.set_title('WMC - Complexidade')\n",
    "    ax1.set_ylabel('WMC M√©dio')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # DIT\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    metrics_by_release[('dit', 'mean')].plot(ax=ax2, marker='s', color='orange', linewidth=2)\n",
    "    ax2.set_title('DIT - Heran√ßa')\n",
    "    ax2.set_ylabel('DIT M√©dio')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # NOC\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    metrics_by_release[('noc', 'mean')].plot(ax=ax3, marker='^', color='brown', linewidth=2)\n",
    "    ax3.set_title('NOC - Filhos')\n",
    "    ax3.set_ylabel('NOC M√©dio')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # CBO\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    metrics_by_release[('cbo', 'mean')].plot(ax=ax4, marker='D', color='green', linewidth=2)\n",
    "    ax4.set_title('CBO - Acoplamento')\n",
    "    ax4.set_ylabel('CBO M√©dio')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # LCOM\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    metrics_by_release[('lcom', 'mean')].plot(ax=ax5, marker='v', color='red', linewidth=2)\n",
    "    ax5.set_title('LCOM - Coes√£o')\n",
    "    ax5.set_ylabel('LCOM M√©dio')\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # RFC\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    metrics_by_release[('rfc', 'mean')].plot(ax=ax6, marker='*', color='cyan', linewidth=2)\n",
    "    ax6.set_title('RFC - Response')\n",
    "    ax6.set_ylabel('RFC M√©dio')\n",
    "    ax6.tick_params(axis='x', rotation=45)\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # LOC\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    metrics_by_release[('loc', 'sum')].plot(ax=ax7, marker='p', color='purple', linewidth=2)\n",
    "    ax7.set_title('LOC - Linhas (Total)')\n",
    "    ax7.set_ylabel('LOC Total')\n",
    "    ax7.tick_params(axis='x', rotation=45)\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'metrics_evolution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distribui√ß√£o das M√©tricas (Boxplots)\n",
    "\n",
    "**√ötil para identificar classes outliers em cada release**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    fig.suptitle('Distribui√ß√£o das 7 M√©tricas CK - Boxplots (para identificar outliers)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    metrics = ['wmc', 'dit', 'noc', 'cbo', 'lcom', 'rfc', 'loc']\n",
    "    titles = ['WMC (Complexidade)', 'DIT (Heran√ßa)', 'NOC (Filhos)', \n",
    "              'CBO (Acoplamento)', 'LCOM (Coes√£o)', 'RFC (Response)', 'LOC (Linhas)']\n",
    "    \n",
    "    for i, (metric, title) in enumerate(zip(metrics, titles), 1):\n",
    "        ax = plt.subplot(3, 3, i)\n",
    "        df_all.boxplot(column=metric, by='release', ax=ax, rot=45)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('')\n",
    "        ax.get_figure().suptitle('')  # Remove t√≠tulo autom√°tico\n",
    "    \n",
    "    plt.suptitle('Distribui√ß√£o das 7 M√©tricas CK por Release - Boxplots', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'metrics_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correla√ß√£o entre M√©tricas (Heatmap)\n",
    "\n",
    "**Mostra rela√ß√µes entre as m√©tricas CK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    correlation_metrics = ['wmc', 'dit', 'noc', 'cbo', 'lcom', 'rfc', 'loc']\n",
    "    corr_matrix = df_all[correlation_metrics].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Matriz de Correla√ß√£o entre M√©tricas CK', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Top Classes com Problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    latest_release = df_all[df_all['release'] == df_all['release'].unique()[-1]]\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"AN√ÅLISE DAS 7 M√âTRICAS CK - √öLTIMA RELEASE ({latest_release['release'].iloc[0]})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nTop 10 Classes com Maior Complexidade (WMC):\")\n",
    "    print(latest_release.nlargest(10, 'wmc')[['class', 'wmc', 'cbo', 'lcom', 'loc']])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Top 10 Classes com Maior Profundidade de Heran√ßa (DIT):\")\n",
    "    print(latest_release.nlargest(10, 'dit')[['class', 'dit', 'wmc', 'cbo']])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Top 10 Classes com Mais Filhos (NOC):\")\n",
    "    print(latest_release.nlargest(10, 'noc')[['class', 'noc', 'dit', 'wmc']])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Top 10 Classes com Maior Acoplamento (CBO):\")\n",
    "    print(latest_release.nlargest(10, 'cbo')[['class', 'cbo', 'wmc', 'lcom']])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Top 10 Classes com Menor Coes√£o (LCOM - valores altos):\")\n",
    "    print(latest_release.nlargest(10, 'lcom')[['class', 'lcom', 'wmc', 'cbo']])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Top 10 Classes com Maior RFC (Response For Class):\")\n",
    "    print(latest_release.nlargest(10, 'rfc')[['class', 'rfc', 'wmc', 'cbo']])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Top 10 Classes com Mais Linhas de C√≥digo (LOC):\")\n",
    "    print(latest_release.nlargest(10, 'loc')[['class', 'loc', 'wmc', 'cbo']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An√°lise de Tend√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    first_release = metrics_by_release.iloc[0]\n",
    "    last_release = metrics_by_release.iloc[-1]\n",
    "    \n",
    "    growth_rates = pd.DataFrame({\n",
    "        'M√©trica': ['WMC', 'DIT', 'NOC', 'CBO', 'LCOM', 'RFC', 'LOC (total)'],\n",
    "        'Primeira Release': [\n",
    "            first_release[('wmc', 'mean')],\n",
    "            first_release[('dit', 'mean')],\n",
    "            first_release[('noc', 'mean')],\n",
    "            first_release[('cbo', 'mean')],\n",
    "            first_release[('lcom', 'mean')],\n",
    "            first_release[('rfc', 'mean')],\n",
    "            first_release[('loc', 'sum')]\n",
    "        ],\n",
    "        '√öltima Release': [\n",
    "            last_release[('wmc', 'mean')],\n",
    "            last_release[('dit', 'mean')],\n",
    "            last_release[('noc', 'mean')],\n",
    "            last_release[('cbo', 'mean')],\n",
    "            last_release[('lcom', 'mean')],\n",
    "            last_release[('rfc', 'mean')],\n",
    "            last_release[('loc', 'sum')]\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    growth_rates['Varia√ß√£o (%)'] = ((growth_rates['√öltima Release'] - growth_rates['Primeira Release']) / growth_rates['Primeira Release'] * 100).round(2)\n",
    "    \n",
    "    print(\"An√°lise de Crescimento das M√©tricas:\")\n",
    "    display(growth_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exportar M√©tricas CK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    metrics_by_release.to_csv(RESULTS_DIR / 'metrics_summary.csv')\n",
    "    growth_rates.to_csv(RESULTS_DIR / 'growth_rates.csv', index=False)\n",
    "    print(\"‚úì M√©tricas CK exportadas:\")\n",
    "    print(\"  - metrics_summary.csv\")\n",
    "    print(\"  - growth_rates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 An√°lise PMD - An√°lise Est√°tica de C√≥digo\n",
    "\n",
    "An√°lise dos problemas detectados pelo PMD (Programming Mistake Detector) em cada release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Carregar dados do PMD\n",
    "all_pmd = []\n",
    "\n",
    "for release_dir in release_dirs:\n",
    "    pmd_csv = release_dir / 'pmd-report.csv'\n",
    "    \n",
    "    if pmd_csv.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(pmd_csv)\n",
    "            df['release'] = release_dir.name\n",
    "            \n",
    "            metadata_file = release_dir / 'metadata.json'\n",
    "            if metadata_file.exists():\n",
    "                with open(metadata_file) as f:\n",
    "                    metadata = json.load(f)\n",
    "                    df['release_date'] = metadata.get('published_date', '')\n",
    "            \n",
    "            all_pmd.append(df)\n",
    "            print(f\"‚úì {release_dir.name}: {len(df)} problemas PMD\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó {release_dir.name}: erro ao ler PMD - {e}\")\n",
    "    else:\n",
    "        print(f\"‚úó {release_dir.name}: sem PMD\")\n",
    "\n",
    "if all_pmd:\n",
    "    df_pmd = pd.concat(all_pmd, ignore_index=True)\n",
    "    print(f\"\\n‚úì Total de problemas PMD: {len(df_pmd)}\")\n",
    "    print(f\"‚úì Releases com PMD: {df_pmd['release'].nunique()}\")\n",
    "else:\n",
    "    df_pmd = pd.DataFrame()\n",
    "    print(\"\\n‚úó Nenhum dado PMD dispon√≠vel\")\n",
    "\n",
    "df_pmd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.1 Estat√≠sticas PMD por Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_pmd.empty:\n",
    "    pmd_by_release = df_pmd.groupby('release').agg({\n",
    "        'Problem': 'count',\n",
    "        'Priority': ['mean', 'min', 'max']\n",
    "    }).round(2)\n",
    "    pmd_by_release.columns = ['Total_Problems', 'Priority_Mean', 'Priority_Min', 'Priority_Max']\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"PROBLEMAS PMD POR RELEASE\")\n",
    "    print(\"=\"*80)\n",
    "    display(pmd_by_release)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTAT√çSTICAS GERAIS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"M√©dia de problemas por release: {pmd_by_release['Total_Problems'].mean():.1f}\")\n",
    "    print(f\"Mediana: {pmd_by_release['Total_Problems'].median():.1f}\")\n",
    "    print(f\"M√≠nimo: {pmd_by_release['Total_Problems'].min()}\")\n",
    "    print(f\"M√°ximo: {pmd_by_release['Total_Problems'].max()}\")\n",
    "    \n",
    "    # Primeira vs √öltima\n",
    "    first = pmd_by_release.iloc[0]\n",
    "    last = pmd_by_release.iloc[-1]\n",
    "    variation = ((last['Total_Problems'] - first['Total_Problems']) / first['Total_Problems'] * 100)\n",
    "    \n",
    "    print(f\"\\nPrimeira release ({pmd_by_release.index[0]}): {first['Total_Problems']:.0f} problemas\")\n",
    "    print(f\"√öltima release ({pmd_by_release.index[-1]}): {last['Total_Problems']:.0f} problemas\")\n",
    "    print(f\"Varia√ß√£o: {variation:+.1f}%\")\n",
    "else:\n",
    "    print(\"Nenhum dado PMD dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.2 Distribui√ß√£o por Prioridade\n",
    "\n",
    "PMD classifica problemas em 4 n√≠veis de prioridade:\n",
    "- **Priority 1:** Cr√≠tico (problemas graves de design/seguran√ßa)\n",
    "- **Priority 2:** Alto\n",
    "- **Priority 3:** M√©dio\n",
    "- **Priority 4:** Baixo (principalmente estilo de c√≥digo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_pmd.empty:\n",
    "    priority_dist = df_pmd['Priority'].value_counts().sort_index()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"DISTRIBUI√á√ÉO POR PRIORIDADE (GERAL)\")\n",
    "    print(\"=\"*80)\n",
    "    for priority, count in priority_dist.items():\n",
    "        pct = count / len(df_pmd) * 100\n",
    "        print(f\"Priority {priority}: {count:5d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('An√°lise PMD - Evolu√ß√£o e Distribui√ß√£o', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Evolu√ß√£o total de problemas\n",
    "    pmd_by_release['Total_Problems'].plot(ax=axes[0, 0], marker='o', color='purple', linewidth=2)\n",
    "    axes[0, 0].set_title('Total de Problemas por Release')\n",
    "    axes[0, 0].set_ylabel('Quantidade')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].axhline(y=pmd_by_release['Total_Problems'].mean(), color='orange',\n",
    "                       linestyle='--', label=f'M√©dia: {pmd_by_release[\"Total_Problems\"].mean():.1f}')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Distribui√ß√£o por prioridade (pizza)\n",
    "    priority_labels = [f'Priority {p}' for p in priority_dist.index]\n",
    "    colors = ['#ff4444', '#ff8844', '#ffcc44', '#88cc44']\n",
    "    priority_dist.plot(kind='pie', ax=axes[0, 1], autopct='%1.1f%%', \n",
    "                       colors=colors[:len(priority_dist)], labels=priority_labels, startangle=90)\n",
    "    axes[0, 1].set_title('Distribui√ß√£o por Prioridade (Geral)')\n",
    "    axes[0, 1].set_ylabel('')\n",
    "    \n",
    "    # 3. Evolu√ß√£o por prioridade\n",
    "    priority_evolution = df_pmd.groupby(['release', 'Priority']).size().unstack(fill_value=0)\n",
    "    priority_evolution.plot(ax=axes[1, 0], marker='o', linewidth=2)\n",
    "    axes[1, 0].set_title('Evolu√ß√£o por Prioridade')\n",
    "    axes[1, 0].set_ylabel('Quantidade')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].legend(title='Priority', labels=[f'Priority {p}' for p in priority_evolution.columns])\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Top 10 regras mais violadas (√∫ltima release)\n",
    "    latest_release_name = df_pmd['release'].unique()[-1]\n",
    "    latest_pmd = df_pmd[df_pmd['release'] == latest_release_name]\n",
    "    top_rules = latest_pmd['Rule'].value_counts().head(10)\n",
    "    top_rules.plot(kind='barh', ax=axes[1, 1], color='darkviolet')\n",
    "    axes[1, 1].set_title(f'Top 10 Regras Violadas ({latest_release_name})')\n",
    "    axes[1, 1].set_xlabel('Quantidade')\n",
    "    axes[1, 1].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'pmd_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Nenhum dado PMD dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.3 Top 10 Regras, Categorias e Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_pmd.empty:\n",
    "    latest_release_name = df_pmd['release'].unique()[-1]\n",
    "    latest_pmd = df_pmd[df_pmd['release'] == latest_release_name].copy()  # .copy() evita SettingWithCopyWarning\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"AN√ÅLISE DETALHADA - √öLTIMA RELEASE ({latest_release_name})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nTotal de problemas: {len(latest_pmd)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"TOP 10 REGRAS MAIS VIOLADAS:\")\n",
    "    print(\"-\"*80)\n",
    "    top_rules = latest_pmd['Rule'].value_counts().head(10)\n",
    "    for i, (rule, count) in enumerate(top_rules.items(), 1):\n",
    "        pct = count / len(latest_pmd) * 100\n",
    "        print(f\"{i:2d}. {rule:50s} : {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"TOP 10 CATEGORIAS (Rule set):\")\n",
    "    print(\"-\"*80)\n",
    "    top_categories = latest_pmd['Rule set'].value_counts().head(10)\n",
    "    for i, (cat, count) in enumerate(top_categories.items(), 1):\n",
    "        pct = count / len(latest_pmd) * 100\n",
    "        print(f\"{i:2d}. {cat:30s} : {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"TOP 10 ARQUIVOS COM MAIS PROBLEMAS:\")\n",
    "    print(\"-\"*80)\n",
    "    # Extrair nome do arquivo do caminho completo\n",
    "    latest_pmd['FileName'] = latest_pmd['File'].apply(lambda x: x.split('/')[-1] if isinstance(x, str) else '')\n",
    "    top_files = latest_pmd['FileName'].value_counts().head(10)\n",
    "    for i, (file, count) in enumerate(top_files.items(), 1):\n",
    "        pct = count / len(latest_pmd) * 100\n",
    "        print(f\"{i:2d}. {file:50s} : {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"PROBLEMAS CR√çTICOS (Priority 1):\")\n",
    "    print(\"-\"*80)\n",
    "    critical = latest_pmd[latest_pmd['Priority'] == 1]\n",
    "    print(f\"Total: {len(critical)} problemas cr√≠ticos ({len(critical)/len(latest_pmd)*100:.1f}%)\")\n",
    "    \n",
    "    if len(critical) > 0:\n",
    "        print(\"\\nTop 5 regras cr√≠ticas:\")\n",
    "        critical_rules = critical['Rule'].value_counts().head(5)\n",
    "        for rule, count in critical_rules.items():\n",
    "            print(f\"  ‚Ä¢ {rule}: {count}\")\n",
    "else:\n",
    "    print(\"Nenhum dado PMD dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.4 Exportar Dados PMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_pmd.empty:\n",
    "    latest_release_name = df_pmd['release'].unique()[-1]\n",
    "    latest_pmd = df_pmd[df_pmd['release'] == latest_release_name]\n",
    "    \n",
    "    # Exportar todos\n",
    "    df_pmd.to_csv(RESULTS_DIR / 'pmd_all_releases.csv', index=False)\n",
    "    print(\"‚úì PMD exportado:\")\n",
    "    print(\"  - pmd_all_releases.csv (todos os problemas)\")\n",
    "    \n",
    "    # √öltima release\n",
    "    latest_pmd.to_csv(RESULTS_DIR / f'pmd_{latest_release_name}.csv', index=False)\n",
    "    print(f\"  - pmd_{latest_release_name}.csv (√∫ltima release)\")\n",
    "    \n",
    "    # Problemas cr√≠ticos\n",
    "    critical = df_pmd[df_pmd['Priority'] == 1]\n",
    "    if not critical.empty:\n",
    "        critical.to_csv(RESULTS_DIR / 'pmd_critical_all.csv', index=False)\n",
    "        print(\"  - pmd_critical_all.csv (prioridade 1)\")\n",
    "    \n",
    "    # Resumo JSON\n",
    "    summary = {\n",
    "        'latest_release': latest_release_name,\n",
    "        'latest_release_problems': len(latest_pmd),\n",
    "        'latest_release_critical': len(latest_pmd[latest_pmd['Priority'] == 1]),\n",
    "        'average_problems_per_release': float(pmd_by_release['Total_Problems'].mean()),\n",
    "        'median_problems_per_release': float(pmd_by_release['Total_Problems'].median()),\n",
    "        'total_releases_analyzed': df_pmd['release'].nunique(),\n",
    "        'most_common_rule': latest_pmd['Rule'].value_counts().index[0] if len(latest_pmd) > 0 else 'N/A',\n",
    "        'most_common_category': latest_pmd['Rule set'].value_counts().index[0] if len(latest_pmd) > 0 else 'N/A'\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / 'pmd_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(\"  - pmd_summary.json\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä RESUMO PMD:\")\n",
    "    print(\"=\"*80)\n",
    "    for key, value in summary.items():\n",
    "        label = key.replace('_', ' ').title()\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {label}: {value:.1f}\")\n",
    "        else:\n",
    "            print(f\"  {label}: {value}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Nenhum dado PMD dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. An√°lise de Bugs - SpotBugs + find-sec-bugs\n",
    "\n",
    "### 10.1 Carregar Bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_spotbugs_xml(xml_file):\n",
    "    \"\"\"Parse SpotBugs XML report.\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        bugs = []\n",
    "        \n",
    "        for bug in root.findall('.//BugInstance'):\n",
    "            bug_info = {\n",
    "                'type': bug.get('type'),\n",
    "                'priority': int(bug.get('priority', 0)),\n",
    "                'rank': int(bug.get('rank', 0)),\n",
    "                'category': bug.get('category'),\n",
    "                'abbrev': bug.get('abbrev', ''),\n",
    "            }\n",
    "            \n",
    "            class_elem = bug.find('.//Class')\n",
    "            bug_info['class'] = class_elem.get('classname', '') if class_elem is not None else ''\n",
    "            \n",
    "            method_elem = bug.find('.//Method')\n",
    "            bug_info['method'] = method_elem.get('name', '') if method_elem is not None else ''\n",
    "            \n",
    "            long_msg = bug.find('.//LongMessage')\n",
    "            bug_info['description'] = long_msg.text if long_msg is not None else ''\n",
    "            \n",
    "            bugs.append(bug_info)\n",
    "        \n",
    "        return bugs\n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {e}\")\n",
    "        return []\n",
    "\n",
    "# Coletar bugs\n",
    "all_bugs = []\n",
    "\n",
    "for release_dir in release_dirs:\n",
    "    spotbugs_xml = release_dir / 'spotbugs-report.xml'\n",
    "    \n",
    "    if spotbugs_xml.exists():\n",
    "        bugs = parse_spotbugs_xml(spotbugs_xml)\n",
    "        for bug in bugs:\n",
    "            bug['release'] = release_dir.name\n",
    "            \n",
    "            metadata_file = release_dir / 'metadata.json'\n",
    "            if metadata_file.exists():\n",
    "                with open(metadata_file) as f:\n",
    "                    metadata = json.load(f)\n",
    "                    bug['release_date'] = metadata.get('published_date', '')\n",
    "        \n",
    "        all_bugs.extend(bugs)\n",
    "        print(f\"‚úì {release_dir.name}: {len(bugs)} bugs\")\n",
    "    else:\n",
    "        print(f\"‚úó {release_dir.name}: sem SpotBugs\")\n",
    "\n",
    "if all_bugs:\n",
    "    df_bugs = pd.DataFrame(all_bugs)\n",
    "    df_bugs['priority_label'] = df_bugs['priority'].map({1: 'HIGH', 2: 'MEDIUM', 3: 'LOW'})\n",
    "    print(f\"\\n‚úì Total de bugs: {len(df_bugs)}\")\n",
    "    print(f\"‚úì Releases com bugs: {df_bugs['release'].nunique()}\")\n",
    "else:\n",
    "    df_bugs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Estat√≠sticas de Bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_bugs.empty:\n",
    "    bugs_by_release = df_bugs.groupby('release').agg({\n",
    "        'type': 'count',\n",
    "        'priority': ['mean', 'min', 'max']\n",
    "    }).round(2)\n",
    "    bugs_by_release.columns = ['Total_Bugs', 'Priority_Mean', 'Priority_Min', 'Priority_Max']\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"BUGS POR RELEASE (cada release √© independente)\")\n",
    "    print(\"=\"*80)\n",
    "    display(bugs_by_release)\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTAT√çSTICAS GERAIS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"M√©dia de bugs por release: {bugs_by_release['Total_Bugs'].mean():.1f}\")\n",
    "    print(f\"Mediana de bugs por release: {bugs_by_release['Total_Bugs'].median():.1f}\")\n",
    "    print(f\"M√≠nimo de bugs em uma release: {bugs_by_release['Total_Bugs'].min()}\")\n",
    "    print(f\"M√°ximo de bugs em uma release: {bugs_by_release['Total_Bugs'].max()}\")\n",
    "    \n",
    "    # Primeira vs √öltima release\n",
    "    first_release = bugs_by_release.iloc[0]\n",
    "    last_release = bugs_by_release.iloc[-1]\n",
    "    variation = ((last_release['Total_Bugs'] - first_release['Total_Bugs']) / first_release['Total_Bugs'] * 100)\n",
    "    \n",
    "    print(f\"\\nPrimeira release ({bugs_by_release.index[0]}): {first_release['Total_Bugs']:.0f} bugs\")\n",
    "    print(f\"√öltima release ({bugs_by_release.index[-1]}): {last_release['Total_Bugs']:.0f} bugs\")\n",
    "    print(f\"Varia√ß√£o: {variation:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 An√°lise da √öltima Release (Estado Atual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_bugs.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Evolu√ß√£o dos Bugs ao Longo das Releases', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Evolu√ß√£o do total de bugs\n",
    "    bugs_by_release['Total_Bugs'].plot(ax=axes[0, 0], marker='o', color='red', linewidth=2)\n",
    "    axes[0, 0].set_title('Total de Bugs por Release')\n",
    "    axes[0, 0].set_ylabel('Quantidade de Bugs')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].axhline(y=bugs_by_release['Total_Bugs'].mean(), color='orange', \n",
    "                       linestyle='--', label=f'M√©dia: {bugs_by_release[\"Total_Bugs\"].mean():.1f}')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Evolu√ß√£o por categoria (top 5)\n",
    "    category_evolution = df_bugs.groupby(['release', 'category']).size().unstack(fill_value=0)\n",
    "    top_categories = df_bugs['category'].value_counts().head(5).index\n",
    "    category_evolution[top_categories].plot(ax=axes[0, 1], marker='o', linewidth=2)\n",
    "    axes[0, 1].set_title('Evolu√ß√£o das Top 5 Categorias')\n",
    "    axes[0, 1].set_ylabel('Quantidade de Bugs')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].legend(title='Categoria', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Evolu√ß√£o por prioridade\n",
    "    priority_evolution = df_bugs.groupby(['release', 'priority_label']).size().unstack(fill_value=0)\n",
    "    priority_evolution.plot(ax=axes[1, 0], marker='o', linewidth=2, \n",
    "                           color=['#ff4444', '#ffaa44'])\n",
    "    axes[1, 0].set_title('Evolu√ß√£o por Prioridade')\n",
    "    axes[1, 0].set_ylabel('Quantidade de Bugs')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].legend(title='Prioridade')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Top 10 tipos de bugs na √∫ltima release\n",
    "    latest_release_name = df_bugs['release'].unique()[-1]\n",
    "    latest_bugs = df_bugs[df_bugs['release'] == latest_release_name]\n",
    "    latest_bugs['type'].value_counts().head(10).plot(kind='barh', ax=axes[1, 1], color='steelblue')\n",
    "    axes[1, 1].set_title(f'Top 10 Tipos de Bugs ({latest_release_name})')\n",
    "    axes[1, 1].set_xlabel('Quantidade')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'bugs_evolution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 Bugs de Seguran√ßa (find-sec-bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_bugs.empty:\n",
    "    security_bugs = df_bugs[df_bugs['category'] == 'SECURITY'].copy()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"BUGS DE SEGURAN√áA (find-sec-bugs)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not security_bugs.empty:\n",
    "        # An√°lise por release\n",
    "        security_by_release = security_bugs.groupby('release').size()\n",
    "        \n",
    "        print(f\"\\nM√©dia de bugs de seguran√ßa por release: {security_by_release.mean():.1f}\")\n",
    "        print(f\"Mediana: {security_by_release.median():.1f}\")\n",
    "        \n",
    "        print(\"\\nBugs de Seguran√ßa por Release:\")\n",
    "        print(security_by_release)\n",
    "        \n",
    "        # √öltima release\n",
    "        latest_release_name = df_bugs['release'].unique()[-1]\n",
    "        latest_security = security_bugs[security_bugs['release'] == latest_release_name]\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"√öLTIMA RELEASE ({latest_release_name}): {len(latest_security)} bugs de seguran√ßa\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(\"\\nTop 10 Tipos de Vulnerabilidades (√∫ltima release):\")\n",
    "        print(latest_security['type'].value_counts().head(10))\n",
    "        \n",
    "        print(\"\\nTop 10 Classes com Bugs de Seguran√ßa (√∫ltima release):\")\n",
    "        print(latest_security['class'].value_counts().head(10))\n",
    "        \n",
    "        # Visualiza√ß√£o\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        fig.suptitle('An√°lise de Bugs de Seguran√ßa', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        security_by_release.plot(ax=axes[0], marker='o', color='darkred', linewidth=2)\n",
    "        axes[0].set_title('Evolu√ß√£o de Bugs de Seguran√ßa')\n",
    "        axes[0].set_ylabel('Quantidade')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].axhline(y=security_by_release.mean(), color='orange', \n",
    "                       linestyle='--', label=f'M√©dia: {security_by_release.mean():.1f}')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        latest_security['type'].value_counts().head(10).plot(kind='barh', ax=axes[1], color='crimson')\n",
    "        axes[1].set_title(f'Top 10 Vulnerabilidades ({latest_release_name})')\n",
    "        axes[1].set_xlabel('Quantidade')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(RESULTS_DIR / 'security_bugs.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n‚úì Nenhum bug de seguran√ßa encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6 Bugs Cr√≠ticos (Prioridade HIGH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_bugs.empty:\n",
    "    critical_bugs = df_bugs[df_bugs['priority'] == 1].copy()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"BUGS CR√çTICOS (Prioridade HIGH)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not critical_bugs.empty:\n",
    "        # An√°lise por release\n",
    "        critical_by_release = critical_bugs.groupby('release').size()\n",
    "        \n",
    "        print(f\"\\nM√©dia de bugs cr√≠ticos por release: {critical_by_release.mean():.1f}\")\n",
    "        print(f\"Mediana: {critical_by_release.median():.1f}\")\n",
    "        \n",
    "        print(\"\\nBugs Cr√≠ticos por Release:\")\n",
    "        print(critical_by_release)\n",
    "        \n",
    "        # √öltima release\n",
    "        latest_release_name = df_bugs['release'].unique()[-1]\n",
    "        latest_critical = critical_bugs[critical_bugs['release'] == latest_release_name]\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"√öLTIMA RELEASE ({latest_release_name}): {len(latest_critical)} bugs cr√≠ticos\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if not latest_critical.empty:\n",
    "            print(\"\\nDETALHES DOS BUGS CR√çTICOS:\")\n",
    "            for idx, bug in latest_critical.iterrows():\n",
    "                print(f\"\\nüî¥ {bug['type']} - {bug['category']}\")\n",
    "                print(f\"   Classe: {bug['class']}\")\n",
    "                if bug['method']:\n",
    "                    print(f\"   M√©todo: {bug['method']}\")\n",
    "                if bug['description']:\n",
    "                    print(f\"   {bug['description'][:150]}...\")\n",
    "                print(\"   \" + \"-\"*76)\n",
    "    else:\n",
    "        print(\"\\n‚úì Nenhum bug cr√≠tico encontrado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.7 Exportar Dados de Bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_bugs.empty:\n",
    "    # Identificar √∫ltima release\n",
    "    latest_release_name = df_bugs['release'].unique()[-1]\n",
    "    latest_bugs = df_bugs[df_bugs['release'] == latest_release_name]\n",
    "    latest_security = security_bugs[security_bugs['release'] == latest_release_name] if not security_bugs.empty else pd.DataFrame()\n",
    "    latest_critical = critical_bugs[critical_bugs['release'] == latest_release_name] if not critical_bugs.empty else pd.DataFrame()\n",
    "    \n",
    "    # Exportar todos os bugs\n",
    "    df_bugs.to_csv(RESULTS_DIR / 'bugs_all_releases.csv', index=False)\n",
    "    print(\"‚úì Bugs exportados:\")\n",
    "    print(\"  - bugs_all_releases.csv (todos os bugs de todas as releases)\")\n",
    "    \n",
    "    # Bugs da √∫ltima release\n",
    "    latest_bugs.to_csv(RESULTS_DIR / f'bugs_{latest_release_name}.csv', index=False)\n",
    "    print(f\"  - bugs_{latest_release_name}.csv (√∫ltima release)\")\n",
    "    \n",
    "    if not security_bugs.empty:\n",
    "        security_bugs.to_csv(RESULTS_DIR / 'security_bugs_all.csv', index=False)\n",
    "        print(\"  - security_bugs_all.csv (todas as releases)\")\n",
    "    \n",
    "    if not critical_bugs.empty:\n",
    "        critical_bugs.to_csv(RESULTS_DIR / 'critical_bugs_all.csv', index=False)\n",
    "        print(\"  - critical_bugs_all.csv (todas as releases)\")\n",
    "    \n",
    "    # Resumo JSON\n",
    "    summary_stats = {\n",
    "        'latest_release': latest_release_name,\n",
    "        'latest_release_bugs': len(latest_bugs),\n",
    "        'latest_release_security_bugs': len(latest_security),\n",
    "        'latest_release_critical_bugs': len(latest_critical),\n",
    "        'average_bugs_per_release': float(bugs_by_release['Total_Bugs'].mean()),\n",
    "        'median_bugs_per_release': float(bugs_by_release['Total_Bugs'].median()),\n",
    "        'total_releases_analyzed': df_bugs['release'].nunique(),\n",
    "        'most_common_bug_type_latest': latest_bugs['type'].value_counts().index[0] if len(latest_bugs) > 0 else 'N/A',\n",
    "        'most_common_category_latest': latest_bugs['category'].value_counts().index[0] if len(latest_bugs) > 0 else 'N/A'\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / 'bugs_summary.json', 'w') as f:\n",
    "        json.dump(summary_stats, f, indent=2)\n",
    "    print(\"  - bugs_summary.json\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä RESUMO GERAL:\")\n",
    "    print(\"=\"*80)\n",
    "    for key, value in summary_stats.items():\n",
    "        label = key.replace('_', ' ').title()\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {label}: {value:.1f}\")\n",
    "        else:\n",
    "            print(f\"  {label}: {value}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Refatora√ß√µes (RefactoringMiner)\n",
    "\n",
    "An√°lise das refatora√ß√µes detectadas pelo RefactoringMiner (arquivo `refactorings-all.json`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "refactoring_file = RESULTS_DIR / 'refactorings-all.json'\n",
    "rows = []\n",
    "commits_com_ref = 0\n",
    "total_commits_refminer = 0\n",
    "\n",
    "if refactoring_file.exists():\n",
    "    with open(refactoring_file, encoding='utf-8') as f:\n",
    "        ref_data = json.load(f)\n",
    "\n",
    "    total_commits_refminer = len(ref_data.get('commits', []))\n",
    "\n",
    "    for commit in ref_data.get('commits', []):\n",
    "        ref_list = commit.get('refactorings', [])\n",
    "        if ref_list:\n",
    "            commits_com_ref += 1\n",
    "            for ref in ref_list:\n",
    "                rows.append({\n",
    "                    'commit': commit.get('sha1'),\n",
    "                    'type': ref.get('type'),\n",
    "                    'description': ref.get('description')\n",
    "                })\n",
    "\n",
    "    df_refs = pd.DataFrame(rows)\n",
    "    print(f'Total de commits avaliados (RefactoringMiner): {total_commits_refminer}')\n",
    "    print(f'Commits com refatoracoes: {commits_com_ref}')\n",
    "    print(f'Total de refatoracoes detectadas: {len(df_refs)}')\n",
    "else:\n",
    "    df_refs = pd.DataFrame()\n",
    "    print('Arquivo refactorings-all.json nao encontrado. Execute a analise primeiro.')\n",
    "\n",
    "df_refs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 An√°lise Avan√ßada - Arquivos e Classes Refatorados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Extrair arquivos e classes de cada refatora√ß√£o\n",
    "if refactoring_file.exists():\n",
    "    file_refactorings = []\n",
    "    class_refactorings = []\n",
    "    \n",
    "    with open(refactoring_file, encoding='utf-8') as f:\n",
    "        ref_data = json.load(f)\n",
    "    \n",
    "    for commit in ref_data.get('commits', []):\n",
    "        for ref in commit.get('refactorings', []):\n",
    "            ref_type = ref.get('type', '')\n",
    "            \n",
    "            # Extrair arquivos de leftSideLocations e rightSideLocations\n",
    "            files_in_ref = set()\n",
    "            for side in ['leftSideLocations', 'rightSideLocations']:\n",
    "                for loc in ref.get(side, []):\n",
    "                    file_path = loc.get('filePath', '')\n",
    "                    if file_path:\n",
    "                        files_in_ref.add(file_path)\n",
    "                        file_refactorings.append({\n",
    "                            'file': file_path,\n",
    "                            'type': ref_type,\n",
    "                            'commit': commit.get('sha1')\n",
    "                        })\n",
    "            \n",
    "            # Extrair classes de codeElement\n",
    "            classes_in_ref = set()\n",
    "            for side in ['leftSideLocations', 'rightSideLocations']:\n",
    "                for loc in ref.get(side, []):\n",
    "                    code_elem = loc.get('codeElement', '')\n",
    "                    if code_elem and loc.get('codeElementType') == 'TYPE_DECLARATION':\n",
    "                        # Extrair nome da classe (ex: \"org.jsoup.parser.Tag\" -> \"Tag\")\n",
    "                        if code_elem:\n",
    "                            # Tentar extrair o nome qualificado da classe\n",
    "                            classes_in_ref.add(code_elem)\n",
    "                            class_refactorings.append({\n",
    "                                'class': code_elem,\n",
    "                                'type': ref_type,\n",
    "                                'commit': commit.get('sha1')\n",
    "                            })\n",
    "    \n",
    "    df_file_refs = pd.DataFrame(file_refactorings) if file_refactorings else pd.DataFrame()\n",
    "    df_class_refs = pd.DataFrame(class_refactorings) if class_refactorings else pd.DataFrame()\n",
    "    \n",
    "    print(f\"‚úì Extra√≠dos {len(df_file_refs)} refatora√ß√µes em arquivos\")\n",
    "    print(f\"‚úì Extra√≠dos {len(df_class_refs)} refatora√ß√µes em classes\")\n",
    "else:\n",
    "    df_file_refs = pd.DataFrame()\n",
    "    df_class_refs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.1 Top 10 Arquivos Mais Refatorados\n",
    "\n",
    "Arquivos que receberam mais refatora√ß√µes ao longo do hist√≥rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_file_refs.empty:\n",
    "    # Top 10 arquivos mais refatorados\n",
    "    top_files = df_file_refs['file'].value_counts().head(10)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TOP 10 ARQUIVOS MAIS REFATORADOS\")\n",
    "    print(\"=\"*80)\n",
    "    print(top_files)\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    fig = plt.figure(figsize=(18, 14))\n",
    "    fig.suptitle('An√°lise de Arquivos Refatorados', fontsize=16, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Layout: 2 colunas\n",
    "    # Coluna esquerda: Top 10 arquivos\n",
    "    # Coluna direita: Top 5 arquivos com detalhamento\n",
    "    \n",
    "    # Top 10 arquivos (truncar nomes longos)\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    top_files_display = top_files.copy()\n",
    "    top_files_display.index = [f.split('/')[-1] if len(f) > 40 else f for f in top_files_display.index]\n",
    "    \n",
    "    top_files_display.plot(kind='barh', ax=ax1, color='steelblue')\n",
    "    ax1.set_title('Top 10 Arquivos Mais Refatorados', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Quantidade de Refatora√ß√µes')\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Top 5 arquivos com tipos de refatora√ß√£o (5 subplots verticais)\n",
    "    top5_files = top_files.head(5).index\n",
    "    \n",
    "    for i, file_path in enumerate(top5_files, 1):\n",
    "        ax = plt.subplot(5, 2, i*2)\n",
    "        \n",
    "        # Filtrar refatora√ß√µes deste arquivo\n",
    "        file_refs = df_file_refs[df_file_refs['file'] == file_path]\n",
    "        type_counts = file_refs['type'].value_counts().head(10)\n",
    "        \n",
    "        # Truncar nome do arquivo para t√≠tulo\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        \n",
    "        # Gr√°fico de barra horizontal\n",
    "        type_counts.plot(kind='barh', ax=ax, color='coral')\n",
    "        ax.set_title(f'{i}. {file_name} ({len(file_refs)} refs)', fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Quantidade', fontsize=8)\n",
    "        ax.tick_params(axis='y', labelsize=7)\n",
    "        ax.tick_params(axis='x', labelsize=8)\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Truncar labels longos\n",
    "        labels = [label.get_text()[:35] + '...' if len(label.get_text()) > 35 else label.get_text() \n",
    "                  for label in ax.get_yticklabels()]\n",
    "        ax.set_yticklabels(labels)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'refactorings_by_file.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Exportar\n",
    "    top_files.to_csv(RESULTS_DIR / 'top_refactored_files.csv', header=['refactoring_count'])\n",
    "    print(f\"\\n‚úì Exportado: top_refactored_files.csv\")\n",
    "else:\n",
    "    print(\"Nenhum dado de arquivos refatorados dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.2 Top 10 Classes Mais Refatoradas\n",
    "\n",
    "Classes que receberam mais refatora√ß√µes e os tipos aplicados em cada uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_class_refs.empty:\n",
    "    # Top 10 classes mais refatoradas\n",
    "    top_classes = df_class_refs['class'].value_counts().head(10)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TOP 10 CLASSES MAIS REFATORADAS\")\n",
    "    print(\"=\"*80)\n",
    "    print(top_classes)\n",
    "    \n",
    "    # Para cada top 10 classe, mostrar quais tipos de refatora√ß√£o foram aplicados\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TIPOS DE REFATORA√á√ÉO POR CLASSE (TOP 10)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for class_name in top_classes.head(10).index:\n",
    "        class_refs = df_class_refs[df_class_refs['class'] == class_name]\n",
    "        type_counts = class_refs['type'].value_counts()\n",
    "        \n",
    "        print(f\"\\nüì¶ {class_name} ({len(class_refs)} refatora√ß√µes)\")\n",
    "        print(\"-\" * 80)\n",
    "        for ref_type, count in type_counts.items():\n",
    "            print(f\"  ‚Ä¢ {ref_type}: {count}\")\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(18, 14))\n",
    "    fig.suptitle('An√°lise de Classes Refatoradas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Top 10 classes (truncar nomes longos - pegar apenas o nome da classe)\n",
    "    top_classes_display = top_classes.copy()\n",
    "    top_classes_display.index = [c.split('.')[-1] if '.' in c else c for c in top_classes_display.index]\n",
    "    \n",
    "    top_classes_display.plot(kind='barh', ax=axes[0], color='darkgreen')\n",
    "    axes[0].set_title('Top 10 Classes Mais Refatoradas')\n",
    "    axes[0].set_xlabel('Quantidade de Refatora√ß√µes')\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    # Heatmap: Top 10 classes x tipos de refatora√ß√£o\n",
    "    top10_classes = top_classes.head(10).index\n",
    "    df_top10 = df_class_refs[df_class_refs['class'].isin(top10_classes)]\n",
    "    heatmap_data = df_top10.groupby(['class', 'type']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Pegar apenas os tipos mais comuns para n√£o poluir o heatmap\n",
    "    top_types = df_top10['type'].value_counts().head(15).index\n",
    "    heatmap_data = heatmap_data[top_types]\n",
    "    \n",
    "    # Truncar nomes de classes no index\n",
    "    heatmap_data.index = [c.split('.')[-1] if '.' in c else c for c in heatmap_data.index]\n",
    "    \n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlOrRd', ax=axes[1], \n",
    "                cbar_kws={'label': 'Quantidade'})\n",
    "    axes[1].set_title('Heatmap: Top 10 Classes x Top 15 Tipos de Refatora√ß√£o')\n",
    "    axes[1].set_xlabel('Tipo de Refatora√ß√£o')\n",
    "    axes[1].set_ylabel('Classe')\n",
    "    axes[1].tick_params(axis='x', rotation=45, labelsize=8)\n",
    "    axes[1].tick_params(axis='y', labelsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'refactorings_by_class.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Exportar\n",
    "    top_classes.to_csv(RESULTS_DIR / 'top_refactored_classes.csv', header=['refactoring_count'])\n",
    "    heatmap_data.to_csv(RESULTS_DIR / 'class_refactoring_heatmap.csv')\n",
    "    print(f\"\\n‚úì Exportado: top_refactored_classes.csv, class_refactoring_heatmap.csv\")\n",
    "else:\n",
    "    print(\"Nenhum dado de classes refatoradas dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.3 Categoriza√ß√£o das Refatora√ß√µes\n",
    "\n",
    "Agrupamento de refatora√ß√µes por categoria sem√¢ntica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_refs.empty:\n",
    "    # Categorizar refatora√ß√µes\n",
    "    def categorize_refactoring(ref_type):\n",
    "        ref_type_lower = ref_type.lower()\n",
    "        \n",
    "        # Categorias baseadas em Fowler's Refactoring Catalog\n",
    "        if any(x in ref_type_lower for x in ['extract method', 'inline method', 'move method', \n",
    "                                               'rename method', 'change method', 'add parameter',\n",
    "                                               'remove parameter', 'parameterize']):\n",
    "            return 'M√©todos'\n",
    "        elif any(x in ref_type_lower for x in ['extract class', 'inline class', 'move class',\n",
    "                                                 'rename class', 'change class', 'split class']):\n",
    "            return 'Classes'\n",
    "        elif any(x in ref_type_lower for x in ['extract variable', 'inline variable', 'rename variable',\n",
    "                                                 'rename attribute', 'rename parameter',\n",
    "                                                 'encapsulate', 'field', 'attribute']):\n",
    "            return 'Vari√°veis/Atributos'\n",
    "        elif any(x in ref_type_lower for x in ['pull up', 'push down', 'extract interface',\n",
    "                                                 'extract superclass', 'collapse hierarchy']):\n",
    "            return 'Hierarquia'\n",
    "        elif any(x in ref_type_lower for x in ['move', 'rename package']):\n",
    "            return 'Pacotes'\n",
    "        else:\n",
    "            return 'Outros'\n",
    "    \n",
    "    df_refs['category'] = df_refs['type'].apply(categorize_refactoring)\n",
    "    \n",
    "    # Estat√≠sticas por categoria\n",
    "    category_stats = df_refs['category'].value_counts()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"REFATORA√á√ïES POR CATEGORIA\")\n",
    "    print(\"=\"*80)\n",
    "    print(category_stats)\n",
    "    print(f\"\\nTotal: {category_stats.sum()} refatora√ß√µes\")\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle('Categoriza√ß√£o das Refatora√ß√µes', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Gr√°fico de pizza\n",
    "    category_stats.plot(kind='pie', ax=axes[0], autopct='%1.1f%%', startangle=90)\n",
    "    axes[0].set_title('Distribui√ß√£o por Categoria')\n",
    "    axes[0].set_ylabel('')\n",
    "    \n",
    "    # Top 5 tipos por categoria (barra empilhada)\n",
    "    category_type_data = []\n",
    "    for cat in category_stats.index:\n",
    "        cat_refs = df_refs[df_refs['category'] == cat]\n",
    "        top5_types = cat_refs['type'].value_counts().head(5)\n",
    "        for ref_type, count in top5_types.items():\n",
    "            category_type_data.append({\n",
    "                'category': cat,\n",
    "                'type': ref_type[:40] + '...' if len(ref_type) > 40 else ref_type,  # Truncar\n",
    "                'count': count\n",
    "            })\n",
    "    \n",
    "    df_cat_type = pd.DataFrame(category_type_data)\n",
    "    pivot = df_cat_type.pivot(index='category', columns='type', values='count').fillna(0)\n",
    "    pivot.plot(kind='barh', stacked=True, ax=axes[1])\n",
    "    axes[1].set_title('Top 5 Tipos por Categoria')\n",
    "    axes[1].set_xlabel('Quantidade')\n",
    "    axes[1].legend(title='Tipo', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'refactorings_by_category.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Exportar\n",
    "    category_stats.to_csv(RESULTS_DIR / 'refactorings_categories.csv', header=['count'])\n",
    "    print(f\"\\n‚úì Exportado: refactorings_categories.csv\")\n",
    "else:\n",
    "    print(\"Nenhum dado de refatora√ß√µes dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.4 Cruzamento: Refatora√ß√µes vs M√©tricas CK\n",
    "\n",
    "Verificar se classes com problemas de qualidade (alto WMC, CBO, LCOM) foram refatoradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_all.empty and not df_class_refs.empty:\n",
    "    # Usar √∫ltima release para m√©tricas CK\n",
    "    latest_release = df_all[df_all['release'] == df_all['release'].unique()[-1]].copy()\n",
    "    \n",
    "    # Identificar classes problem√°ticas (top 20% em WMC, CBO, LCOM)\n",
    "    wmc_threshold = latest_release['wmc'].quantile(0.80)\n",
    "    cbo_threshold = latest_release['cbo'].quantile(0.80)\n",
    "    lcom_threshold = latest_release['lcom'].quantile(0.80)\n",
    "    \n",
    "    problematic_classes = latest_release[\n",
    "        (latest_release['wmc'] >= wmc_threshold) |\n",
    "        (latest_release['cbo'] >= cbo_threshold) |\n",
    "        (latest_release['lcom'] >= lcom_threshold)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CRUZAMENTO: CLASSES PROBLEM√ÅTICAS vs REFATORA√á√ïES\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Classes problem√°ticas identificadas: {len(problematic_classes)}\")\n",
    "    print(f\"  ‚Ä¢ WMC >= {wmc_threshold:.1f}: {len(latest_release[latest_release['wmc'] >= wmc_threshold])}\")\n",
    "    print(f\"  ‚Ä¢ CBO >= {cbo_threshold:.1f}: {len(latest_release[latest_release['cbo'] >= cbo_threshold])}\")\n",
    "    print(f\"  ‚Ä¢ LCOM >= {lcom_threshold:.1f}: {len(latest_release[latest_release['lcom'] >= lcom_threshold])}\")\n",
    "    \n",
    "    # Contar refatora√ß√µes por classe\n",
    "    refactored_classes_count = df_class_refs['class'].value_counts().to_dict()\n",
    "    \n",
    "    # Adicionar contagem de refatora√ß√µes √†s classes problem√°ticas\n",
    "    problematic_classes['refactoring_count'] = problematic_classes['class'].apply(\n",
    "        lambda x: refactored_classes_count.get(x, 0)\n",
    "    )\n",
    "    \n",
    "    # Classes problem√°ticas que foram refatoradas\n",
    "    refactored_problematic = problematic_classes[problematic_classes['refactoring_count'] > 0]\n",
    "    not_refactored_problematic = problematic_classes[problematic_classes['refactoring_count'] == 0]\n",
    "    \n",
    "    print(f\"\\nClasses problem√°ticas que FORAM refatoradas: {len(refactored_problematic)} ({len(refactored_problematic)/len(problematic_classes)*100:.1f}%)\")\n",
    "    print(f\"Classes problem√°ticas que N√ÉO foram refatoradas: {len(not_refactored_problematic)} ({len(not_refactored_problematic)/len(problematic_classes)*100:.1f}%)\")\n",
    "    \n",
    "    # Top 10 classes problem√°ticas mais refatoradas\n",
    "    if not refactored_problematic.empty:\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"TOP 10 CLASSES PROBLEM√ÅTICAS MAIS REFATORADAS:\")\n",
    "        print(\"-\"*80)\n",
    "        top_refactored = refactored_problematic.nlargest(10, 'refactoring_count')[\n",
    "            ['class', 'wmc', 'cbo', 'lcom', 'refactoring_count']\n",
    "        ]\n",
    "        print(top_refactored.to_string())\n",
    "    \n",
    "    # Classes problem√°ticas que mais precisam de aten√ß√£o (alto WMC/CBO/LCOM e poucas refatora√ß√µes)\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"TOP 10 CLASSES PROBLEM√ÅTICAS COM POUCAS REFATORA√á√ïES (precisam de aten√ß√£o):\")\n",
    "    print(\"-\"*80)\n",
    "    problematic_classes['problem_score'] = (\n",
    "        problematic_classes['wmc'] / wmc_threshold +\n",
    "        problematic_classes['cbo'] / cbo_threshold +\n",
    "        problematic_classes['lcom'] / lcom_threshold\n",
    "    )\n",
    "    needs_attention = problematic_classes.nsmallest(10, 'refactoring_count')[\n",
    "        ['class', 'wmc', 'cbo', 'lcom', 'refactoring_count', 'problem_score']\n",
    "    ]\n",
    "    print(needs_attention.to_string())\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Cruzamento: Refatora√ß√µes vs M√©tricas CK', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Classes problem√°ticas refatoradas vs n√£o refatoradas (pizza)\n",
    "    refactored_status = pd.Series({\n",
    "        'Refatoradas': len(refactored_problematic),\n",
    "        'N√£o Refatoradas': len(not_refactored_problematic)\n",
    "    })\n",
    "    refactored_status.plot(kind='pie', ax=axes[0, 0], autopct='%1.1f%%', \n",
    "                          colors=['lightgreen', 'lightcoral'], startangle=90)\n",
    "    axes[0, 0].set_title('Classes Problem√°ticas: Status de Refatora√ß√£o')\n",
    "    axes[0, 0].set_ylabel('')\n",
    "    \n",
    "    # 2. WMC vs Refactorings (scatter)\n",
    "    axes[0, 1].scatter(problematic_classes['wmc'], problematic_classes['refactoring_count'], \n",
    "                      alpha=0.6, color='blue')\n",
    "    axes[0, 1].set_title('WMC vs Quantidade de Refatora√ß√µes')\n",
    "    axes[0, 1].set_xlabel('WMC (Complexidade)')\n",
    "    axes[0, 1].set_ylabel('Refatora√ß√µes')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. CBO vs Refactorings (scatter)\n",
    "    axes[1, 0].scatter(problematic_classes['cbo'], problematic_classes['refactoring_count'], \n",
    "                      alpha=0.6, color='green')\n",
    "    axes[1, 0].set_title('CBO vs Quantidade de Refatora√ß√µes')\n",
    "    axes[1, 0].set_xlabel('CBO (Acoplamento)')\n",
    "    axes[1, 0].set_ylabel('Refatora√ß√µes')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. LCOM vs Refactorings (scatter)\n",
    "    axes[1, 1].scatter(problematic_classes['lcom'], problematic_classes['refactoring_count'], \n",
    "                      alpha=0.6, color='red')\n",
    "    axes[1, 1].set_title('LCOM vs Quantidade de Refatora√ß√µes')\n",
    "    axes[1, 1].set_xlabel('LCOM (Coes√£o)')\n",
    "    axes[1, 1].set_ylabel('Refatora√ß√µes')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'refactorings_vs_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Exportar\n",
    "    problematic_classes[['class', 'wmc', 'cbo', 'lcom', 'refactoring_count', 'problem_score']].to_csv(\n",
    "        RESULTS_DIR / 'problematic_classes_refactorings.csv', index=False\n",
    "    )\n",
    "    print(f\"\\n‚úì Exportado: problematic_classes_refactorings.csv\")\n",
    "else:\n",
    "    print(\"Dados de m√©tricas CK ou refatora√ß√µes n√£o dispon√≠veis para cruzamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2.5 Estat√≠sticas Descritivas - Refatora√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if not df_refs.empty:\n",
    "    # Estat√≠sticas descritivas\n",
    "    print(\"=\"*80)\n",
    "    print(\"ESTAT√çSTICAS DESCRITIVAS - REFATORA√á√ïES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Refatora√ß√µes por commit\n",
    "    refs_per_commit = df_refs.groupby('commit').size()\n",
    "    \n",
    "    print(f\"\\nTotal de commits analisados: {total_commits_refminer}\")\n",
    "    print(f\"Commits com refatora√ß√µes: {commits_com_ref} ({commits_com_ref/total_commits_refminer*100:.1f}%)\")\n",
    "    print(f\"Commits sem refatora√ß√µes: {total_commits_refminer - commits_com_ref} ({(total_commits_refminer - commits_com_ref)/total_commits_refminer*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTotal de refatora√ß√µes detectadas: {len(df_refs)}\")\n",
    "    print(f\"Tipos √∫nicos de refatora√ß√£o: {df_refs['type'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nRefatora√ß√µes por commit (estat√≠sticas):\")\n",
    "    print(f\"  ‚Ä¢ M√©dia: {refs_per_commit.mean():.2f}\")\n",
    "    print(f\"  ‚Ä¢ Mediana: {refs_per_commit.median():.1f}\")\n",
    "    print(f\"  ‚Ä¢ Desvio padr√£o: {refs_per_commit.std():.2f}\")\n",
    "    print(f\"  ‚Ä¢ M√≠nimo: {refs_per_commit.min()}\")\n",
    "    print(f\"  ‚Ä¢ M√°ximo: {refs_per_commit.max()}\")\n",
    "    print(f\"  ‚Ä¢ Percentil 75%: {refs_per_commit.quantile(0.75):.1f}\")\n",
    "    print(f\"  ‚Ä¢ Percentil 90%: {refs_per_commit.quantile(0.90):.1f}\")\n",
    "    \n",
    "    # Top 5 commits com mais refatora√ß√µes\n",
    "    print(f\"\\nTop 5 commits com mais refatora√ß√µes:\")\n",
    "    top_commits = refs_per_commit.nlargest(5)\n",
    "    for commit, count in top_commits.items():\n",
    "        print(f\"  ‚Ä¢ {commit[:8]}... : {count} refatora√ß√µes\")\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle('Estat√≠sticas de Refatora√ß√µes por Commit', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Histograma de refatora√ß√µes por commit\n",
    "    refs_per_commit.hist(bins=30, ax=axes[0], color='steelblue', edgecolor='black')\n",
    "    axes[0].set_title('Distribui√ß√£o de Refatora√ß√µes por Commit')\n",
    "    axes[0].set_xlabel('Quantidade de Refatora√ß√µes')\n",
    "    axes[0].set_ylabel('Frequ√™ncia (commits)')\n",
    "    axes[0].axvline(refs_per_commit.mean(), color='red', linestyle='--', \n",
    "                   label=f'M√©dia: {refs_per_commit.mean():.2f}')\n",
    "    axes[0].axvline(refs_per_commit.median(), color='orange', linestyle='--',\n",
    "                   label=f'Mediana: {refs_per_commit.median():.1f}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Boxplot\n",
    "    refs_per_commit.plot(kind='box', ax=axes[1], vert=True)\n",
    "    axes[1].set_title('Boxplot: Refatora√ß√µes por Commit')\n",
    "    axes[1].set_ylabel('Quantidade de Refatora√ß√µes')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'refactorings_statistics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Resumo final JSON\n",
    "    summary = {\n",
    "        'total_commits': total_commits_refminer,\n",
    "        'commits_with_refactorings': commits_com_ref,\n",
    "        'commits_without_refactorings': total_commits_refminer - commits_com_ref,\n",
    "        'percentage_commits_with_refs': round(commits_com_ref/total_commits_refminer*100, 2),\n",
    "        'total_refactorings': len(df_refs),\n",
    "        'unique_refactoring_types': df_refs['type'].nunique(),\n",
    "        'refactorings_per_commit': {\n",
    "            'mean': round(refs_per_commit.mean(), 2),\n",
    "            'median': round(refs_per_commit.median(), 1),\n",
    "            'std': round(refs_per_commit.std(), 2),\n",
    "            'min': int(refs_per_commit.min()),\n",
    "            'max': int(refs_per_commit.max()),\n",
    "            'percentile_75': round(refs_per_commit.quantile(0.75), 1),\n",
    "            'percentile_90': round(refs_per_commit.quantile(0.90), 1)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / 'refactorings_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úì Exportado: refactorings_summary.json\")\n",
    "else:\n",
    "    print(\"Nenhum dado de refatora√ß√µes dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Resumo e Pr√≥ximos Passos\n",
    "\n",
    "### ‚úÖ O que foi analisado:\n",
    "1. **M√©tricas CK** - Complexidade (WMC), Acoplamento (CBO), Coes√£o (LCOM), etc.\n",
    "2. **Distribui√ß√£o** - Boxplots para identificar classes outliers.\n",
    "3. **Correla√ß√µes** - Heatmap mostrando rela√ß√µes entre m√©tricas.\n",
    "4. **PMD - An√°lise Est√°tica** Evolu√ß√£o de problemas de c√≥digo, prioridades, regras violadas.\n",
    "5. **Bugs Gerais** - SpotBugs (todos os bugs detectados).\n",
    "6. **Bugs de Seguran√ßa** - find-sec-bugs (vulnerabilidades).\n",
    "7. **Bugs Cr√≠ticos** - Prioridade HIGH.\n",
    "8. **Refatora√ß√µes** - Hist√≥rico completo analisado pelo RefactoringMiner.\n",
    "9. **An√°lise Avan√ßada de Refatora√ß√µes**:\n",
    "   - Top 10 arquivos mais refatorados\n",
    "   - Top 10 classes mais refatoradas + tipos aplicados\n",
    "   - Categoriza√ß√£o por tipo de refatora√ß√£o (M√©todos, Classes, Hierarquia, etc.)\n",
    "   - Cruzamento com m√©tricas CK (classes problem√°ticas foram refatoradas?)\n",
    "   - Estat√≠sticas descritivas (refatora√ß√µes por commit)\n",
    "\n",
    "### üìÅ Arquivos gerados:\n",
    "\n",
    "**M√©tricas CK**\n",
    "- `metrics_summary.csv` - Estat√≠sticas por release.\n",
    "- `growth_rates.csv` - Taxa de crescimento.\n",
    "- `metrics_evolution.png` - Gr√°ficos de evolu√ß√£o.\n",
    "- `metrics_distribution.png` - Boxplots.\n",
    "- `correlation_matrix.png` - Heatmap de correla√ß√µes.\n",
    "\n",
    "**PMD - An√°lise Est√°tica**\n",
    "- `pmd_all_releases.csv` - Todos os problemas PMD.\n",
    "- `pmd_{release}.csv` - Problemas da √∫ltima release.\n",
    "- `pmd_critical_all.csv` - Problemas cr√≠ticos (Priority 1).\n",
    "- `pmd_summary.json` - Resumo estat√≠stico.\n",
    "- `pmd_analysis.png` - Evolu√ß√£o e distribui√ß√£o por prioridade.\n",
    "\n",
    "**Bugs**\n",
    "- `bugs_all_releases.csv` - Todos os bugs.\n",
    "- `security_bugs_all.csv` - Bugs de seguran√ßa.\n",
    "- `critical_bugs_all.csv` - Bugs cr√≠ticos.\n",
    "- `bugs_summary.json` - Resumo estat√≠stico.\n",
    "- `bugs_evolution.png` - Visualiza√ß√µes gerais.\n",
    "- `security_bugs.png` - Visualiza√ß√µes de seguran√ßa.\n",
    "\n",
    "**Refatora√ß√µes (RefactoringMiner)**\n",
    "- `refactorings-all.json` - Refatora√ß√µes detectadas em commits.\n",
    "- `refactoring-miner.log` - Log completo do processamento (stdout/stderr).\n",
    "- `refactorings_by_type.csv` - Quantidade de refatora√ß√µes por tipo.\n",
    "- `top_refactored_files.csv` - Top arquivos mais refatorados.\n",
    "- `top_refactored_classes.csv` - Top classes mais refatoradas.\n",
    "- `class_refactoring_heatmap.csv` - Heatmap classes x tipos.\n",
    "- `refactorings_categories.csv` - Distribui√ß√£o por categoria.\n",
    "- `problematic_classes_refactorings.csv` - Cruzamento com m√©tricas CK.\n",
    "- `refactorings_summary.json` - Estat√≠sticas descritivas.\n",
    "- `refactorings_by_file.png` - Visualiza√ß√µes de arquivos.\n",
    "- `refactorings_by_class.png` - Visualiza√ß√µes de classes + heatmap.\n",
    "- `refactorings_by_category.png` - Categoriza√ß√£o.\n",
    "- `refactorings_vs_metrics.png` - Cruzamento com m√©tricas CK.\n",
    "- `refactorings_statistics.png` - Estat√≠sticas por commit.\n",
    "\n",
    "### üéØ Como usar:\n",
    "1. **Identificar problemas** - Use Top Classes (m√©tricas CK), Top Regras (PMD), boxplots e tipos de refatora√ß√£o.\n",
    "2. **Priorizar** - Foque em:\n",
    "   - **PMD Priority 1** (problemas cr√≠ticos de design/seguran√ßa)\n",
    "   - Bugs de seguran√ßa/cr√≠ticos (SpotBugs)\n",
    "   - Classes problem√°ticas que N√ÉO foram refatoradas (veja `problematic_classes_refactorings.csv`)\n",
    "   - Arquivos/classes mais refatorados (hotspots de mudan√ßa)\n",
    "3. **Refatorar** - Classes com WMC/CBO/LCOM altos + muitos problemas PMD s√£o candidatos naturais.\n",
    "4. **Submeter PRs** - Corrija bugs, problemas PMD cr√≠ticos e planeje refatora√ß√µes compat√≠veis.\n",
    "5. **Documentar** - Utilize gr√°ficos e tabelas no artigo cient√≠fico, cruzando m√©tricas, PMD, bugs e refatora√ß√µes.\n",
    "\n",
    "### üí° Dicas para Pull Requests:\n",
    "- **Problemas PMD Priority 1** s√£o candidatos excelentes para PRs r√°pidos (design/boas pr√°ticas).\n",
    "- Bugs de seguran√ßa s√£o sempre bem-vindos; priorize-os.\n",
    "- Comece com corre√ß√µes simples (PMD Priority 3-4, bugs LOW) e evolua para cr√≠ticos.\n",
    "- Classes com LCOM alto + muitos problemas PMD -> aplicar **Split Responsibility**.\n",
    "- M√©todos com WMC alto + regras PMD -> aplicar **Extract Method**.\n",
    "- Use o ranking de refatora√ß√µes para justificar decis√µes.\n",
    "- **Classes problem√°ticas com poucas refatora√ß√µes** s√£o candidatas priorit√°rias.\n",
    "\n",
    "### üìä Insights para Artigo Cient√≠fico:\n",
    "- **Correla√ß√£o m√©tricas x refatora√ß√µes:** Classes com alta complexidade foram refatoradas?\n",
    "- **PMD vs M√©tricas CK:** Classes com alto WMC/CBO t√™m mais problemas PMD?\n",
    "- **Evolu√ß√£o da qualidade:** Problemas PMD diminu√≠ram ao longo das releases?\n",
    "- **Padr√µes de refatora√ß√£o:** Quais categorias s√£o mais comuns?\n",
    "- **Hotspots de mudan√ßa:** Arquivos/classes mais refatorados indicam √°reas cr√≠ticas.\n",
    "- **D√≠vida t√©cnica:** Classes problem√°ticas sem refatora√ß√µes + muitos problemas PMD = d√≠vida t√©cnica acumulada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
